{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5fc0db-8671-45eb-9006-8236cda57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(1,\"/home/showalte/research/prob_seq_queries/\")\n",
    "from seq_queries.utils import read_pkl, write_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b52721a-1c0f-4001-b451-3899e8e6176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_data(experiment, dataset, h, s, root=\"../data\", \n",
    "            methods=['beam_search_is_hybrid','importance_sampling'],\n",
    "            gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "        data_dict = {}\n",
    "        gt_type=None\n",
    "        for method in methods:\n",
    "            template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "            template_file=f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_{method.replace('_','-')}_{h}h_{s}s*.pkl\"\n",
    "            pot_pattern = os.path.join(template_path,template_file)\n",
    "            pot_paths = glob.glob(pot_pattern)\n",
    "            assert len(pot_paths) == 1,\\\n",
    "                f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "            data_dict[method]= read_pkl(pot_paths[0])\n",
    "            data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "        for gt_method in gt_methods:\n",
    "            try:\n",
    "                template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "                template_file=f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_{gt_method.replace('_','-')}_{h}h_{s}s*.pkl\"\n",
    "                pot_pattern = os.path.join(template_path,template_file)\n",
    "                pot_paths = glob.glob(pot_pattern)\n",
    "                assert len(pot_paths) == 1,\\\n",
    "                    f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "                print(pot_paths[0])\n",
    "                data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "                data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "                data_dict['gt_type'] = gt_method\n",
    "                return data_dict\n",
    "            except: pass\n",
    "        assert False,\"Could not find ground truth\"\n",
    "        return None\n",
    "                \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87bf22-bcf6-49ea-b43c-9c6bd34216f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate fields\n",
    "- ground_truth/beam_search_lb\n",
    "- Importance sampling estimate\n",
    "- Hybrid estimate\n",
    "- Importance sampling variance\n",
    "- Hybrid variance\n",
    "\n",
    "# General Metadata\n",
    "- dataset_name\n",
    "- experiment_name\n",
    "- history_id\n",
    "- Excluded term\n",
    "- sequence_length\n",
    "- history_length\n",
    "- total_sequence_length\n",
    "\n",
    "# Sampling metadata\n",
    "- num_mc_samples (sub_estimates)\n",
    "- sample_model_iters\n",
    "\n",
    "# Hybrid data\n",
    "- hybrid_model_iters\n",
    "\n",
    "# Beam search metadata\n",
    "- min_variance\n",
    "- search_model_iters\n",
    "- min_variance_reduction\n",
    "- true_coverage\n",
    "- restricted_coverage\n",
    "- num_beams\n",
    "- top_k\n",
    "- top_p\n",
    "- (beam search) interpolation_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bff8c61a-43ae-4901-8cf0-1f34078701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_hybrid_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "#     samp_estimates = samp_dict['hybrid_bs_is_estimate'][:,:len(sub_estimates)]\n",
    "#     if not sub_estimates:\n",
    "#         if len(samp_estimates.shape) ==3:\n",
    "#             assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "#             (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is\" +\n",
    "#              f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "#             samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "#                                           samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "#             assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "#         if len(samp_estimates.shape) ==2:\n",
    "#             samp_estimates = torch.gather(samp_estimates,1,\n",
    "#                                               samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "#         df = pd.DataFrame(samp_estimates)\n",
    "#         df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "#         df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "#         df[f'{sample_type}_est_variance'] = samp_dist['hyrbid_var']\n",
    "        \n",
    "#     else:\n",
    "#         assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "#         (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "#          f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "#         print(samp_estimates.shape)\n",
    "#         if len(samp_estimates.shape) == 2:\n",
    "#             samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "#             samp_var = pd.DataFrame(samp_dict['hybrid_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "#             model_iters_df = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "#             df = pd.melt(samp_estimates,value_vars=sub_estimates)\n",
    "#             df.columns = ['num_samples','sample_estimate']\n",
    "#             print(df.head())\n",
    "#             var_df =  pd.melt(samp_var,value_vars=sub_estimates)\n",
    "#             var_df.columns = ['num_samples','variance']\n",
    "#             iter_df = pd.melt(model_iters_df,value_vars=sub_estimates)\n",
    "#             iter_df.columns = ['num_samples','model_iters']\n",
    "#             df[f'{sample_type}_model_iters']=iter_df['model_iters']\n",
    "#             df[f'{sample_type}_est_variance']=var_df['variance']\n",
    "#             print(\"length 2\")\n",
    "#             print(df.shape)\n",
    "            \n",
    "#         elif len(samp_estimates.shape) == 3:\n",
    "#             df_list = []\n",
    "#             for i in range(len(sub_estimates)):\n",
    "#                 df = pd.DataFrame(\n",
    "#                             torch.gather(samp_estimates[:,i],1,\n",
    "#                                       samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "#                         )\n",
    "#                 df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "#                 df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "#                 df[f'{sample_type}_est_variance'] = samp_dict['sample_est_var'][:,i]\n",
    "#                 print(df.shape)\n",
    "#                 df_list.append(df)\n",
    "            \n",
    "#             df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "#         else:\n",
    "#             assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "#     assert df.shape[-1] == 4, f\"DF shape is {df.shape}\"\n",
    "#     df.columns = ['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "#                   f'{sample_type}_model_iters',f'{sample_type}_est_variance']\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "def flatten_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "    print(samp_dict.keys())\n",
    "    samp_estimates = samp_dict['sample_estimates'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "            (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is\" +\n",
    "             f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_est_variance'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            samp_var = pd.DataFrame(samp_dict['sample_estimate_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters_df = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            df = pd.melt(samp_estimates,value_vars=sub_estimates)\n",
    "            df.columns = ['num_samples','sample_estimate']\n",
    "            var_df =  pd.melt(samp_var,value_vars=sub_estimates)\n",
    "            var_df.columns = ['num_samples','variance']\n",
    "            iter_df = pd.melt(model_iters_df,value_vars=sub_estimates)\n",
    "            iter_df.columns = ['num_samples','model_iters']\n",
    "            df[f'{sample_type}_model_iters']=iter_df['model_iters']\n",
    "            df[f'{sample_type}_est_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "                df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                samp_est_var = torch.gather(samp_dict['sample_estimate_var'][:,i],1,\n",
    "                                            samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                                            \n",
    "                df[f'{sample_type}_est_variance'] = samp_est_var\n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    assert df.shape[-1] == 4, f\"DF shape is {df.shape}\"\n",
    "    df.columns = ['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "                  f'{sample_type}_model_iters',f'{sample_type}_est_variance']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def flatten_gt(data_dict,gt_type):\n",
    "    gt_dict = data_dict[gt_type]\n",
    "    # gt = gt_dict['bs_lower_bound']\n",
    "    gt = torch.gather(gt_dict['dist_lower_bound'],1,\n",
    "                      gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "    assert len(gt.shape) == 1,\\\n",
    "    f\"Ground truth has {len(gt.shape)} dimensions\"\n",
    "    df = pd.DataFrame(gt,columns=['ground_truth'])\n",
    "    for item in ['true_coverage','restricted_coverage']:\n",
    "        df[item] = [gti.item() for gti in gt_dict[item]]\n",
    "    # df[\"gt_model_iters\"] = gt_dict['model_iters']\n",
    "    df['gt_type'] = gt_type\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def flatten_experiment(data_dict,experiment, dataset,h,s,\n",
    "     global_agreement_vals= ['excluded_terms']):\n",
    "    sub_estimates = sorted(list(\n",
    "        set(data_dict['importance_sampling']['metadata']['sub_estimates']) &\n",
    "        set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n",
    "    sub_est_len = 1 if not sub_estimates else len(sub_estimates)\n",
    "    importance_df = flatten_sampling(data_dict['importance_sampling'],sub_estimates,sample_type ='importance')\n",
    "    print(importance_df.shape)\n",
    "    hybrid_df = flatten_sampling(data_dict['beam_search_is_hybrid'],sub_estimates,sample_type ='hybrid')\n",
    "    print(hybrid_df.shape)\n",
    "    hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\n",
    "    gt_df = flatten_gt(data_dict,data_dict['gt_type'])\n",
    "    print(\"GT\")\n",
    "    print(gt_df.shape)\n",
    "    gt_df = pd.concat([gt_df]*sub_est_len,axis=0,ignore_index=True)\n",
    "    final_df = pd.concat([importance_df,hybrid_df,gt_df],axis=1)\n",
    "    # print(hybrid_df.head())\n",
    "    # print(importance_df.head())\n",
    "    # print(final_df.isnull().sum())\n",
    "    \n",
    "    # Metadata checks\n",
    "    is_metadata = ['top_k','top_p']\n",
    "    bs_metadata = ['min_variance','min_var_reduction','num_beams']\n",
    "    for m in is_metadata:\n",
    "        final_df[m] = data_dict['importance_sampling']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df[m] = data_dict[data_dict['gt_type']]['metadata'][m]\n",
    "    final_df['interp_func'] = str(data_dict[data_dict['gt_type']]['metadata']['interp_func']).split(\" \")[1]\n",
    "    \n",
    "    \n",
    "    final_df['dataset_name'] = dataset\n",
    "    final_df['hist_len'] = h\n",
    "    final_df['total_seq_len'] = s\n",
    "    final_df['seq_len'] = s-h\n",
    "    sequence_ids = list(range(data_dict['importance_sampling']['sample_estimates'].shape[0]))*sub_est_len\n",
    "    excluded_terms = data_dict['importance_sampling']['excluded_terms'].numpy().tolist()*sub_est_len\n",
    "    final_df['sequence_id'] = sequence_ids\n",
    "    final_df['excluded_term'] = excluded_terms\n",
    "    \n",
    "    return final_df\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cb936c89-eb0e-42cd-923b-8a60a9fc167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\"val_dl\"]\n",
    "dataset = [\"apps\"]\n",
    "lengths = [(13,15),(12,15)]\n",
    "def flatten_experiments(experiments, datasets, lengths):\n",
    "    data_list = []\n",
    "    for experiment in experiments:\n",
    "        for dataset in datasets:\n",
    "            for h,s in lengths:\n",
    "                # try:\n",
    "                    \n",
    "                    data = get_experiment_data(experiment,dataset,h,s)\n",
    "                    df = flatten_experiment(data,experiment, dataset, h,s)\n",
    "                    # print(df.head())\n",
    "                    # print(df.columns)\n",
    "                    # print(df.shape)\n",
    "                    # sys.exit(1)\n",
    "                    data_list.append(df)\n",
    "                # except Exception as e:\n",
    "                #     print(\"Could not flatten: Experiment: {} | Dataset: {} | lengths: {}\"\\\n",
    "                #           .format(experiment, dataset, (h,s)))\n",
    "                    \n",
    "    # print(len(data_list))\n",
    "    data_df = pd.concat(data_list,axis = 0)\n",
    "    ordering = [ 'dataset_name','sequence_id','seq_len', 'excluded_term', 'gt_type','ground_truth','importance_sampling_est','hybrid_sampling_est', \n",
    "                'num_mc_samples', 'importance_model_iters','hybrid_model_iters',\n",
    "       'importance_est_variance',  'hybrid_est_variance',\n",
    "         'true_coverage', 'restricted_coverage',  'top_k', 'top_p', 'min_variance',\n",
    "       'min_var_reduction', 'num_beams', 'interp_func',\n",
    "       'hist_len', 'total_seq_len', ]\n",
    "    data_df = data_df[ordering]\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return data_df\n",
    "                \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62c51bbf-1517-42cc-8ed2-b99b496d041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/ground_truth/amazon/val_dl/val-dl_amazon_ground-truth_13h_15s.pkl\n",
      "dict_keys(['sample_estimates', 'sample_estimate_var', 'sample_estimate_mean', 'model_iters', 'metadata', 'excluded_terms'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 0 expected index [6384, 1] to be smaller than self [4096, 30] apart from dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f331f60d5531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_dl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amazon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-9d8b2c9b7a5d>\u001b[0m in \u001b[0;36mflatten_experiments\u001b[0;34m(experiments, datasets, lengths)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0;31m# print(df.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;31m# print(df.columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-b7720a100013>\u001b[0m in \u001b[0;36mflatten_experiment\u001b[0;34m(data_dict, experiment, dataset, h, s, global_agreement_vals)\u001b[0m\n\u001b[1;32m    148\u001b[0m         set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n\u001b[1;32m    149\u001b[0m     \u001b[0msub_est_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msub_estimates\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_estimates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mimportance_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'importance_sampling'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_estimates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mhybrid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'beam_search_is_hybrid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_estimates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'hybrid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-b7720a100013>\u001b[0m in \u001b[0;36mflatten_sampling\u001b[0;34m(samp_dict, sub_estimates, sample_type)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_estimates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 df = pd.DataFrame(\n\u001b[0;32m--> 107\u001b[0;31m                             torch.gather(samp_estimates[:,i],1,\n\u001b[0m\u001b[1;32m    108\u001b[0m                                       samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n\u001b[1;32m    109\u001b[0m                         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Size does not match at dimension 0 expected index [6384, 1] to be smaller than self [4096, 30] apart from dimension 1"
     ]
    }
   ],
   "source": [
    "df = flatten_experiments(['val_dl'],['amazon'],[(13,15),(12,15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ce843b1-19fd-4a08-bd5e-a76576456916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38304, 23)\n",
      "dataset_name                   0\n",
      "sequence_id                    0\n",
      "seq_len                        0\n",
      "excluded_term                  0\n",
      "gt_type                    13728\n",
      "ground_truth               13728\n",
      "importance_sampling_est        0\n",
      "hybrid_sampling_est            0\n",
      "num_mc_samples                 0\n",
      "importance_model_iters         0\n",
      "hybrid_model_iters             0\n",
      "importance_est_variance        0\n",
      "hybrid_est_variance            0\n",
      "true_coverage              13728\n",
      "restricted_coverage        13728\n",
      "top_k                          0\n",
      "top_p                          0\n",
      "min_variance                   0\n",
      "min_var_reduction              0\n",
      "num_beams                      0\n",
      "interp_func                    0\n",
      "hist_len                       0\n",
      "total_seq_len                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data['importance_sampling']['metadata']['sub_estimates']\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b010b1e-e070-4f9b-85bf-141fd935acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>excluded_term</th>\n",
       "      <th>gt_type</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>importance_sampling_est</th>\n",
       "      <th>hybrid_sampling_est</th>\n",
       "      <th>num_mc_samples</th>\n",
       "      <th>importance_model_iters</th>\n",
       "      <th>...</th>\n",
       "      <th>true_coverage</th>\n",
       "      <th>restricted_coverage</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_p</th>\n",
       "      <th>min_variance</th>\n",
       "      <th>min_var_reduction</th>\n",
       "      <th>num_beams</th>\n",
       "      <th>interp_func</th>\n",
       "      <th>hist_len</th>\n",
       "      <th>total_seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apps</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>ground_truth</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lin_interp</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apps</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>ground_truth</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.159075</td>\n",
       "      <td>0.177607</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lin_interp</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apps</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>ground_truth</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lin_interp</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apps</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>ground_truth</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.015489</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lin_interp</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apps</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>ground_truth</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lin_interp</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name  sequence_id  seq_len  excluded_term       gt_type  \\\n",
       "0         apps            0        2             18  ground_truth   \n",
       "1         apps            1        2             19  ground_truth   \n",
       "2         apps            2        2             62  ground_truth   \n",
       "3         apps            3        2             26  ground_truth   \n",
       "4         apps            4        2             55  ground_truth   \n",
       "\n",
       "   ground_truth  importance_sampling_est  hybrid_sampling_est  num_mc_samples  \\\n",
       "0      0.004943                 0.002610             0.001628              10   \n",
       "1      0.003039                 0.159075             0.177607              10   \n",
       "2      0.001873                 0.002914             0.002125              10   \n",
       "3      0.001658                 0.017911             0.015489              10   \n",
       "4      0.002419                 0.000287             0.000269              10   \n",
       "\n",
       "   importance_model_iters  ...  true_coverage  restricted_coverage  top_k  \\\n",
       "0                     150  ...       0.217077                  1.0      0   \n",
       "1                     150  ...       0.033593                  1.0      0   \n",
       "2                     150  ...       0.010515                  1.0      0   \n",
       "3                     150  ...       0.041589                  1.0      0   \n",
       "4                     150  ...       0.013752                  1.0      0   \n",
       "\n",
       "   top_p  min_variance  min_var_reduction  num_beams  interp_func  hist_len  \\\n",
       "0      0         False                0.9        1.0   lin_interp        13   \n",
       "1      0         False                0.9        1.0   lin_interp        13   \n",
       "2      0         False                0.9        1.0   lin_interp        13   \n",
       "3      0         False                0.9        1.0   lin_interp        13   \n",
       "4      0         False                0.9        1.0   lin_interp        13   \n",
       "\n",
       "   total_seq_len  \n",
       "0             15  \n",
       "1             15  \n",
       "2             15  \n",
       "3             15  \n",
       "4             15  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a3e8a10-b1b5-4498-bc4a-90eaa5ecbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hybrid_model_iters</th>\n",
       "      <th>importance_model_iters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13722.000000</td>\n",
       "      <td>13722.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>383.422679</td>\n",
       "      <td>7400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1617.802994</td>\n",
       "      <td>8940.12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>589.750000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56701.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hybrid_model_iters  importance_model_iters\n",
       "count        13722.000000             13722.00000\n",
       "mean           383.422679              7400.00000\n",
       "std           1617.802994              8940.12442\n",
       "min             20.000000               200.00000\n",
       "25%             20.000000               200.00000\n",
       "50%             27.000000              2000.00000\n",
       "75%            589.750000             20000.00000\n",
       "max          56701.000000             20000.00000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['hybrid_model_iters','importance_model_iters']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a52b7fd-4659-494d-9ff3-13584d46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('padhraic_shakespeare_17-18_20.csv',index=None)\n",
    "# df.to_csv('padhraic_amazon_12-13_15.csv',index=None)\n",
    "df.to_csv('padhraic_apps_12-13_15.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d4da0-609f-40e6-ad58-0c5d761c8463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
