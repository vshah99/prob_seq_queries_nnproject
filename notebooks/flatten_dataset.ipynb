{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5fc0db-8671-45eb-9006-8236cda57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(1,\"/home/showalte/research/prob_seq_queries/\")\n",
    "from seq_queries.utils import read_pkl, write_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87bf22-bcf6-49ea-b43c-9c6bd34216f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate fields\n",
    "- ground_truth/beam_search_lb\n",
    "- Importance sampling estimate\n",
    "- Hybrid estimate\n",
    "- Importance sampling variance\n",
    "- Hybrid variance\n",
    "\n",
    "# General Metadata\n",
    "- dataset_name\n",
    "- experiment_name\n",
    "- history_id\n",
    "- Excluded term\n",
    "- sequence_length\n",
    "- history_length\n",
    "- total_sequence_length\n",
    "\n",
    "# Sampling metadata\n",
    "- num_mc_samples (sub_estimates)\n",
    "- sample_model_iters\n",
    "\n",
    "# Hybrid data\n",
    "- hybrid_model_iters\n",
    "\n",
    "# Beam search metadata\n",
    "- min_variance\n",
    "- search_model_iters\n",
    "- min_variance_reduction\n",
    "- true_coverage\n",
    "- restricted_coverage\n",
    "- num_beams\n",
    "- top_k\n",
    "- top_p\n",
    "- (beam search) interpolation_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52721a-1c0f-4001-b451-3899e8e6176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_experiment_data(experiment, dataset, h, s, root=\"../data\", \n",
    "#             methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "#             gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "#         data_dict = {}\n",
    "#         gt_type=None\n",
    "#         for method in methods:\n",
    "#             template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "#             template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#             f\"{method.replace('_','-')}_{h}h_{s}s*mc.pkl\")\n",
    "#             pot_pattern = os.path.join(template_path,template_file)\n",
    "#             pot_paths = glob.glob(pot_pattern)\n",
    "#             assert len(pot_paths) == 1,\\\n",
    "#                 f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#             print(method, pot_paths[0])\n",
    "#             data_dict[method]= read_pkl(pot_paths[0])\n",
    "#             data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#         for gt_method in gt_methods:\n",
    "#             try:\n",
    "#                 template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "#                 # Don't match on model budget terms\n",
    "#                 template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#                                f\"{gt_method.replace('_','-')}_{h}h_{s}s*[!t].pkl\")\n",
    "#                 pot_pattern = os.path.join(template_path,template_file)\n",
    "#                 pot_paths = glob.glob(pot_pattern)\n",
    "#                 assert len(pot_paths) == 1,\\\n",
    "#                     f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#                 print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "#                 data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "#                 data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#                 data_dict['gt_type'] = gt_method\n",
    "#                 return data_dict\n",
    "#             except: pass\n",
    "#         assert False,\"Could not find ground truth\"\n",
    "#         print()\n",
    "#         return None\n",
    "    \n",
    "def get_experiment_data_model_budget(experiment, dataset, h, s, root=\"../data\", \n",
    "            methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "            gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "        data_dict = {}\n",
    "        gt_type=None\n",
    "        for method in methods:\n",
    "            template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "            template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\"\n",
    "            + f\"{method.replace('_','-')}_{h}h_{s}s*{'' if method == 'beam_search_is_hybrid' else 'model-budget'}.pkl\")\n",
    "            pot_pattern = os.path.join(template_path,template_file)\n",
    "            pot_paths = glob.glob(pot_pattern)\n",
    "            assert len(pot_paths) == 1,\\\n",
    "                f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "            # print(method,pot_paths[0])\n",
    "            print(method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "            data_dict[method]= read_pkl(pot_paths[0])\n",
    "            data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "        for gt_method in gt_methods:\n",
    "            try:\n",
    "                template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "                template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "                               f\"{gt_method.replace('_','-')}_{h}h_{s}s*.pkl\")\n",
    "                pot_pattern = os.path.join(template_path,template_file)\n",
    "                pot_paths = glob.glob(pot_pattern)\n",
    "                assert len(pot_paths) == 1,\\\n",
    "                    f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "                print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "                data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "                data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "                data_dict['gt_type'] = gt_method\n",
    "                return data_dict\n",
    "            except: pass\n",
    "        assert False,\"Could not find ground truth\"\n",
    "        return None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff8c61a-43ae-4901-8cf0-1f34078701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_search(samp_dict,sub_estimates,search_type=\"beam_search\"):\n",
    "    samp_estimates = samp_dict['bs_lower_bound'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of bs_lower_bounds is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_num_beams'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            beams = pd.DataFrame(samp_dict['num_beams'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            true_cov = pd.DataFrame(samp_dict['true_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            restr_cov = pd.DataFrame(samp_dict['restricted_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{search_type}_lb',samp_estimates),\n",
    "                ('model_iters',model_iters),\n",
    "                ('num_beams',beams),\n",
    "                ('true_coverage',true_cov),\n",
    "                ('restricted_coverage',restr_cov),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                df[f'{search_type}_{name}']=df[name]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                df[f'{search_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                df[f'{search_type}_num_beams'] = samp_dict['num_beams'][:,i]\n",
    "                df[f'{search_type}_true_coverage'] = samp_dict['true_coverage'][:,i]\n",
    "                df[f'{search_type}_restricted_coverage'] = samp_dict['restricted_coverage'][:,i]\n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['lb','model_iters','num_beams','true_coverage','restricted_coverage']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{search_type}_{s}' for s in res_cols]\n",
    "    df['gt_type'] = 'ground_truth' if search_type=='ground_truth' else 'beam_search'\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def flatten_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "    samp_estimates = samp_dict['sample_estimates'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "            (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is \" +\n",
    "             f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_est_variance'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            samp_var = pd.DataFrame(samp_dict['sample_estimate_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            sub_estimate_num_samples = None\n",
    "            if sample_type != 'hybrid':\n",
    "                sub_estimate_num_samples = pd.DataFrame(samp_dict['num_mc_samples'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{sample_type}_sampling_est',samp_estimates),\n",
    "                ('num_mc_samples',sub_estimate_num_samples),\n",
    "                ('model_iters',model_iters),\n",
    "                ('variance',samp_var),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df[f'{sample_type}_{name}']=df[name]\n",
    "            if df_type == \"hybrid\":\n",
    "                df['num_mc_samples'] = df['num_samples']\n",
    "                df = df[['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "                         'model_iters','variance']]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                if sample_type == \"hybrid\": df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "                else: df.insert(0,'num_mc_samples',samp_dict['num_mc_samples'][:,i])\n",
    "                df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                samp_est_var = torch.gather(samp_dict['sample_estimate_var'][:,i],1,\n",
    "                                            samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                                            \n",
    "                df[f'{sample_type}_variance'] = samp_est_var\n",
    "                \n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['num_mc_samples','sampling_est','model_iters','variance']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{sample_type}_{s}' for s in res_cols]\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten_gt(data_dict,gt_type):\n",
    "    gt_dict = data_dict[gt_type]\n",
    "    print(gt_dict.keys())\n",
    "    # gt = gt_dict['bs_lower_bound']\n",
    "    gt = torch.gather(gt_dict['bs_lower_bound'],1,\n",
    "                      gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "    assert len(gt.shape) == 1,\\\n",
    "    f\"Ground truth has {len(gt.shape)} dimensions\"\n",
    "    df = pd.DataFrame(gt,columns=['ground_truth'])\n",
    "    for item in ['true_coverage','restricted_coverage','model_iters']:\n",
    "        df[f\"gt_{item}\"] = [gti.item() for gti in gt_dict[item]]\n",
    "    # df[\"gt_model_iters\"] = gt_dict['model_iters']\n",
    "    df['gt_type'] = gt_type\n",
    "    df['gt_num_beams'] = gt_dict['metadata']['num_beams']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def flatten_experiment(data_dict,experiment, dataset,h,s,\n",
    "     global_agreement_vals= ['excluded_terms']):\n",
    "    sub_estimates = sorted(list(\n",
    "        # set(data_dict['importance_sampling']['metadata']['sub_estimates']) &\n",
    "        # set(data_dict['random_sampling']['metadata']['sub_estimates']) &\n",
    "        set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n",
    "    sub_est_len = 1 if not sub_estimates else len(sub_estimates)\n",
    "    \n",
    "    importance_df = flatten_sampling(data_dict['importance_sampling'],sub_estimates,sample_type ='importance')\n",
    "    random_df = flatten_sampling(data_dict['random_sampling'],sub_estimates,sample_type ='random')\n",
    "    hybrid_df = flatten_sampling(data_dict['beam_search_is_hybrid'],sub_estimates,sample_type ='hybrid')\n",
    "    search_df = flatten_search(data_dict['beam_search'],sub_estimates,search_type='beam_search')\n",
    "    # hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\n",
    "    \n",
    "    gt_df = flatten_gt(data_dict,data_dict['gt_type'])\n",
    "    gt_df = pd.concat([gt_df]*sub_est_len,axis=0,ignore_index=True)\n",
    "    final_df = pd.concat([random_df,importance_df,hybrid_df,search_df,gt_df],axis=1)\n",
    "    \n",
    "    # Metadata checks\n",
    "    is_metadata = ['top_k','top_p']\n",
    "    hybrid_metadata = ['min_variance','min_var_reduction']\n",
    "    bs_metadata = []\n",
    "    gt_metadata = []\n",
    "    for m in is_metadata:\n",
    "        final_df['is_' + m] = data_dict['importance_sampling']['metadata'][m]\n",
    "    for m in hybrid_metadata:\n",
    "        final_df['hybrid_' + m] = data_dict['beam_search_is_hybrid']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['bs_lb_' + m] = data_dict['beam_search']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['gt_' + m] = data_dict[data_dict['gt_type']]['metadata'][m]\n",
    "    final_df['interp_func'] = str(data_dict[data_dict['gt_type']]['metadata']['interp_func']).split(\" \")[1]\n",
    "    \n",
    "    \n",
    "    final_df['dataset_name'] = dataset\n",
    "    final_df['hist_len'] = h\n",
    "    final_df['total_seq_len'] = s\n",
    "    final_df['seq_len'] = s-h\n",
    "    sequence_ids = list(range(data_dict['importance_sampling']['sample_estimates'].shape[0]))*sub_est_len\n",
    "    excluded_terms = data_dict['importance_sampling']['excluded_terms'].numpy().tolist()*sub_est_len\n",
    "    final_df['sequence_id'] = sequence_ids\n",
    "    final_df['excluded_term'] = excluded_terms\n",
    "                 \n",
    "    # ==== Phase shift stuff ====\n",
    "    # phase_shifts = read_pkl(\"/srv/disk00/samshow/amazon/amazon_phase_trans.pkl\")\n",
    "    # phase_shift_val_inds = read_pkl(\"../data/amazon/amazon_val_dl_transition_inds.pkl\")\n",
    "    # phase_shifts = phase_shifts[phase_shift_val_inds].numpy().tolist()\n",
    "    # print(phase_shift_val_inds.shape, final_df.shape)\n",
    "    # final_df['phase_shifts'] = phase_shifts * sub_est_len\n",
    "    # final_df['phase_shifts'] -=1\n",
    "    \n",
    "    return final_df\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb936c89-eb0e-42cd-923b-8a60a9fc167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\"val_dl\"]\n",
    "dataset = [\"apps\"]\n",
    "lengths = [(13,15),(12,15)]\n",
    "def flatten_experiments(experiments, datasets, lengths,model_budget=False):\n",
    "    data_list = []\n",
    "    for experiment in experiments:\n",
    "        for dataset in datasets:\n",
    "            for h,s in lengths:\n",
    "                # try:\n",
    "                    \n",
    "                    if model_budget:\n",
    "                        data = get_experiment_data(experiment,dataset,h,s)\n",
    "                    else:\n",
    "                        data = get_experiment_data_model_budget(experiment,dataset,h,s)\n",
    "                        \n",
    "                    df = flatten_experiment(data,experiment, dataset, h,s)\n",
    "                    \n",
    "#                     print(df.head())\n",
    "#                     print(df.columns)\n",
    "#                     print(df.shape)\n",
    "#                     sys.exit(1)\n",
    "                    \n",
    "                    data_list.append(df)\n",
    "                    \n",
    "    # print(len(data_list))\n",
    "    data_df = pd.concat(data_list,axis = 0)\n",
    "    ordering = [ 'dataset_name','sequence_id','seq_len', 'excluded_term', 'gt_type','ground_truth',\n",
    "                'random_sampling_est','importance_sampling_est','hybrid_sampling_est', 'beam_search_lb',\n",
    "                'random_num_mc_samples', 'importance_num_mc_samples','hybrid_num_mc_samples',\n",
    "                'gt_model_iters','random_model_iters', #continues to next line\n",
    "                'importance_model_iters','hybrid_model_iters','beam_search_model_iters',\n",
    "                'random_variance','importance_variance',  'hybrid_variance',\n",
    "                'gt_true_coverage', 'gt_restricted_coverage', 'gt_num_beams',\n",
    "                'beam_search_true_coverage', 'beam_search_restricted_coverage', 'beam_search_num_beams',\n",
    "                'is_top_k','is_top_p',\n",
    "                'hybrid_min_variance','hybrid_min_var_reduction', \n",
    "                'interp_func','hist_len', 'total_seq_len']#, 'phase_shifts']\n",
    "    data_df = data_df[ordering]\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return data_df\n",
    "                \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62c51bbf-1517-42cc-8ed2-b99b496d041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/moocs/val_dl/val-dl_moocs_beam-search-is-hybrid_13h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/moocs/val_dl/val-dl_moocs_importance-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/moocs/val_dl/val-dl_moocs_random-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/moocs/val_dl/val-dl_moocs_beam-search_13h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/moocs/val_dl/val-dl_moocs_ground-truth_13h_15s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/moocs/val_dl/val-dl_moocs_beam-search-is-hybrid_12h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/moocs/val_dl/val-dl_moocs_importance-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/moocs/val_dl/val-dl_moocs_random-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/moocs/val_dl/val-dl_moocs_beam-search_12h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  beam_search \n",
      " ../data/beam_search/moocs/val_dl/val-dl_moocs_beam-search_12h_15s_model-budget.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-08ffa9455e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_dl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'moocs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# df1 = flatten_experiments(['val_dl'],['shakespeare'],[(18,20),(17,20)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df2 = flatten_experiments(['val_dl'],['apps'],[(13,15),(12,15)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# df3 = flatten_experiments(['val_dl'],['amazon'],[(13,15),(12,15)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9f3226050056>\u001b[0m in \u001b[0;36mflatten_experiments\u001b[0;34m(experiments, datasets, lengths, model_budget)\u001b[0m\n\u001b[1;32m     14\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_data_model_budget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#                     print(df.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8ba0f61286a1>\u001b[0m in \u001b[0;36mflatten_experiment\u001b[0;34m(data_dict, experiment, dataset, h, s, global_agreement_vals)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mgt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mgt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msub_est_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhybrid_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearch_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgt_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8ba0f61286a1>\u001b[0m in \u001b[0;36mflatten_gt\u001b[0;34m(data_dict, gt_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# gt = gt_dict['bs_lower_bound']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     gt = torch.gather(gt_dict['bs_lower_bound'],1,\n\u001b[0m\u001b[1;32m    151\u001b[0m                       gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n\u001b[1;32m    152\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "df = flatten_experiments(['val_dl'],['moocs'],[(13,15),(12,15)])\n",
    "# df1 = flatten_experiments(['val_dl'],['shakespeare'],[(18,20),(17,20)])\n",
    "# df2 = flatten_experiments(['val_dl'],['apps'],[(13,15),(12,15)])\n",
    "# df3 = flatten_experiments(['val_dl'],['amazon'],[(13,15),(12,15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686d012-ca67-4160-aace-cabe4dc2d6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce843b1-19fd-4a08-bd5e-a76576456916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_model_iters</th>\n",
       "      <th>hybrid_model_iters</th>\n",
       "      <th>beam_search_model_iters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10909</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>2964</td>\n",
       "      <td>2963</td>\n",
       "      <td>2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>2628</td>\n",
       "      <td>2628</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>2976</td>\n",
       "      <td>2975</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>3000</td>\n",
       "      <td>2998</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>2730</td>\n",
       "      <td>2730</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>2922</td>\n",
       "      <td>2922</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>2565</td>\n",
       "      <td>2564</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10918</th>\n",
       "      <td>2046</td>\n",
       "      <td>2045</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10920</th>\n",
       "      <td>2985</td>\n",
       "      <td>2983</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>2940</td>\n",
       "      <td>2938</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10922</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>2967</td>\n",
       "      <td>2965</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>2943</td>\n",
       "      <td>2941</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>3000</td>\n",
       "      <td>2999</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>2505</td>\n",
       "      <td>2503</td>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>2430</td>\n",
       "      <td>2430</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>1653</td>\n",
       "      <td>1651</td>\n",
       "      <td>1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10929</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10932</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10933</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10934</th>\n",
       "      <td>2688</td>\n",
       "      <td>2688</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10935</th>\n",
       "      <td>1938</td>\n",
       "      <td>1936</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>1662</td>\n",
       "      <td>1660</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>2520</td>\n",
       "      <td>2520</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>1674</td>\n",
       "      <td>1673</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10941</th>\n",
       "      <td>2940</td>\n",
       "      <td>2940</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10942</th>\n",
       "      <td>2799</td>\n",
       "      <td>2798</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10943</th>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10944</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10946</th>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>2916</td>\n",
       "      <td>2914</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>2559</td>\n",
       "      <td>2558</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>2385</td>\n",
       "      <td>2383</td>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>2844</td>\n",
       "      <td>2842</td>\n",
       "      <td>2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>2883</td>\n",
       "      <td>2881</td>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>1752</td>\n",
       "      <td>1751</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>2655</td>\n",
       "      <td>2653</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_model_iters  hybrid_model_iters  beam_search_model_iters\n",
       "10909                    2019                2019                     2019\n",
       "10910                    2964                2963                     2965\n",
       "10911                    2919                2919                     2919\n",
       "10912                    2628                2628                     2629\n",
       "10913                    2976                2975                     2977\n",
       "10914                    3000                2998                     3001\n",
       "10915                    2730                2730                     2731\n",
       "10916                    2922                2922                     2923\n",
       "10917                    2565                2564                     2565\n",
       "10918                    2046                2045                     2047\n",
       "10919                    2985                2985                     2985\n",
       "10920                    2985                2983                     2985\n",
       "10921                    2940                2938                     2941\n",
       "10922                    2967                2966                     2967\n",
       "10923                    2967                2965                     2967\n",
       "10924                    2943                2941                     2943\n",
       "10925                    3000                2999                     3001\n",
       "10926                    2505                2503                     2505\n",
       "10927                    2430                2430                     2431\n",
       "10928                    1653                1651                     1653\n",
       "10929                    2979                2978                     2979\n",
       "10930                    2991                2991                     2991\n",
       "10931                    1695                1695                     1695\n",
       "10932                    2979                2978                     2979\n",
       "10933                    2967                2966                     2967\n",
       "10934                    2688                2688                     2689\n",
       "10935                    1938                1936                     1939\n",
       "10936                    1662                1660                     1663\n",
       "10937                    2589                2589                     2589\n",
       "10938                    2520                2520                     2521\n",
       "10939                    1674                1673                     1675\n",
       "10940                    2967                2967                     2967\n",
       "10941                    2940                2940                     2941\n",
       "10942                    2799                2798                     2799\n",
       "10943                    2859                2859                     2859\n",
       "10944                    3003                3003                     3003\n",
       "10945                    2895                2895                     2895\n",
       "10946                    2040                2040                     2041\n",
       "10947                    2916                2914                     2917\n",
       "10948                    2559                2558                     2559\n",
       "10949                    2949                2949                     2949\n",
       "10950                    1881                1881                     1881\n",
       "10951                    2385                2383                     2385\n",
       "10952                    3003                3003                     3003\n",
       "10953                    2844                2842                     2845\n",
       "10954                    2883                2881                     2883\n",
       "10955                    2997                2997                     2997\n",
       "10956                    1752                1751                     1753\n",
       "10957                    2655                2653                     2655\n",
       "10958                    2139                2139                     2139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['importance_sampling']['metadata']['sub_estimates']\n",
    "# print(df.shape)\n",
    "# print(df.isnull().sum())\n",
    "# df.phase_shifts.describe()\n",
    "# df[['importance_model_iters','hybrid_model_iters','beam_search_model_iters']].tail(50)\n",
    "# df[['hybrid_num_mc_samples', 'importance_num_mc_samples','beam_search_num_beams']].head(50)\n",
    "# df[['beam_search_true_coverage','beam_search_restricted_coverage','beam_search_num_beams']].tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81963683-e69a-4cbf-be8f-970918de1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b17f57-5661-4ffc-8b42-d94827b114ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['shakespeare', 0, 2, ..., 'lin_interp', 18, 20],\n",
       "       ['shakespeare', 1, 2, ..., 'lin_interp', 18, 20],\n",
       "       ['shakespeare', 2, 2, ..., 'lin_interp', 18, 20],\n",
       "       ...,\n",
       "       ['shakespeare', 2284, 3, ..., 'lin_interp', 17, 20],\n",
       "       ['shakespeare', 2285, 3, ..., 'lin_interp', 17, 20],\n",
       "       ['shakespeare', 2286, 3, ..., 'lin_interp', 17, 20]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b010b1e-e070-4f9b-85bf-141fd935acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'importance')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = df[df['phase_shifts'] > 10]\n",
    "plt.scatter(df['ground_truth'],df['importance_sampling_est'])\n",
    "plt.title(\"importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3e8a10-b1b5-4498-bc4a-90eaa5ecbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_est_variance</th>\n",
       "      <th>hybrid_est_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.191800e+04</td>\n",
       "      <td>2.191800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.688037e-05</td>\n",
       "      <td>3.907905e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.492985e-04</td>\n",
       "      <td>8.797111e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.860333e-20</td>\n",
       "      <td>1.116206e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.422974e-09</td>\n",
       "      <td>1.191007e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.011587e-08</td>\n",
       "      <td>1.700204e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.072154e-07</td>\n",
       "      <td>1.139661e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.445925e-02</td>\n",
       "      <td>4.038442e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_est_variance  hybrid_est_variance\n",
       "count             2.191800e+04         2.191800e+04\n",
       "mean              3.688037e-05         3.907905e-06\n",
       "std               6.492985e-04         8.797111e-05\n",
       "min               2.860333e-20         1.116206e-19\n",
       "25%               4.422974e-09         1.191007e-09\n",
       "50%               4.011587e-08         1.700204e-08\n",
       "75%               3.072154e-07         1.139661e-07\n",
       "max               4.445925e-02         4.038442e-03"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['importance_est_variance','hybrid_est_variance']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed16f5a-8501-46b6-8e3e-3d4f3a55b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name               0\n",
       "sequence_id                0\n",
       "seq_len                    0\n",
       "excluded_term              0\n",
       "gt_type                    0\n",
       "ground_truth               0\n",
       "importance_sampling_est    0\n",
       "hybrid_sampling_est        0\n",
       "num_mc_samples             0\n",
       "importance_model_iters     0\n",
       "hybrid_model_iters         0\n",
       "importance_est_variance    0\n",
       "hybrid_est_variance        0\n",
       "true_coverage              0\n",
       "restricted_coverage        0\n",
       "top_k                      0\n",
       "top_p                      0\n",
       "min_variance               0\n",
       "min_var_reduction          0\n",
       "num_beams                  0\n",
       "interp_func                0\n",
       "hist_len                   0\n",
       "total_seq_len              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a52b7fd-4659-494d-9ff3-13584d46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('shakespeare_17-18_20.csv',index=None)\n",
    "df2.to_csv('amazon_12-13_15.csv',index=None)\n",
    "df3.to_csv('apps_12-13_15.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea7d4da0-609f-40e6-ad58-0c5d761c8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dict = read_pkl(\"/srv/disk00/samshow/amazon/amazon_text_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb6f3eab-1f61-4c3e-bf7c-2ff76eb144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon_dict['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19594098-def2-47ac-8f3a-059d760179fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580, 16])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0b0cc01-7d4b-4203-88ea-d367dd1d10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 16., 16., 16., 11.,  3., 27., 27.,  9.,  9.,  9., 23., 16., 16.,\n",
       "        16.,  8.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c73676-c082-46a2-997d-1cea95e17256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63844580/63844580 [17:23<00:00, 61164.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "trans = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    trans.append(torch.unique_consecutive(data[i,1:]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b36271e-5d00-43d2-af28-de548ec74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torch.LongTensor(trans).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c83ae82d-e144-4f7b-9fa1-855591a0f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36efdf43-a1a5-43b0-97c4-9f85633c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pkl(trans, \"/srv/disask00/samshow/amazon/amazon_phase_trans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60ad3b21-6ab1-4788-af46-5b60a4823228",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vals = []\n",
    "for i in range(1,trans.max()+1):\n",
    "    trans_vals.append((trans == i).sum().item()/trans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "299b9ef8-a587-479e-821d-6b244e68101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_perc_per_phase_shift = [0.059163910233257073,\n",
    " 0.020707521296247856,\n",
    " 0.056485656260876024,\n",
    " 0.04778584180520884,\n",
    " 0.07297364944682853,\n",
    " 0.07653857226408256,\n",
    " 0.09382401763783238,\n",
    " 0.10168632952084578,\n",
    " 0.1102257544806466,\n",
    " 0.10986890351538063,\n",
    " 0.09992870185691566,\n",
    " 0.0774158276238954,\n",
    " 0.047934671979986396,\n",
    " 0.020711280425057224,\n",
    " 0.004749361652939059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ba0a-3b52-4c66-93bd-57bbea35dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
