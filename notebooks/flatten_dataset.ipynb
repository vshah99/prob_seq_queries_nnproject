{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5fc0db-8671-45eb-9006-8236cda57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "sys.path.insert(1,\"/home/showalte/research/prob_seq_queries/\")\n",
    "from seq_queries.utils import read_pkl, write_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87bf22-bcf6-49ea-b43c-9c6bd34216f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Estimate fields\n",
    "- ground_truth/beam_search_lb\n",
    "- Importance sampling estimate\n",
    "- Hybrid estimate\n",
    "- Importance sampling variance\n",
    "- Hybrid variance\n",
    "\n",
    "# General Metadata\n",
    "- dataset_name\n",
    "- experiment_name\n",
    "- history_id\n",
    "- Excluded term\n",
    "- sequence_length\n",
    "- history_length\n",
    "- total_sequence_length\n",
    "\n",
    "# Sampling metadata\n",
    "- num_mc_samples (sub_estimates)\n",
    "- sample_model_iters\n",
    "\n",
    "# Hybrid data\n",
    "- hybrid_model_iters\n",
    "\n",
    "# Beam search metadata\n",
    "- min_variance\n",
    "- search_model_iters\n",
    "- min_variance_reduction\n",
    "- true_coverage\n",
    "- restricted_coverage\n",
    "- num_beams\n",
    "- top_k\n",
    "- top_p\n",
    "- (beam search) interpolation_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b52721a-1c0f-4001-b451-3899e8e6176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_experiment_data(experiment, dataset, h, s, root=\"../data\", \n",
    "#             methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "#             gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "#         data_dict = {}\n",
    "#         gt_type=None\n",
    "#         for method in methods:\n",
    "#             template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "#             template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#             f\"{method.replace('_','-')}_{h}h_{s}s*mc.pkl\")\n",
    "#             pot_pattern = os.path.join(template_path,template_file)\n",
    "#             pot_paths = glob.glob(pot_pattern)\n",
    "#             assert len(pot_paths) == 1,\\\n",
    "#                 f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#             print(method, pot_paths[0])\n",
    "#             data_dict[method]= read_pkl(pot_paths[0])\n",
    "#             data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#         for gt_method in gt_methods:\n",
    "#             try:\n",
    "#                 template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "#                 # Don't match on model budget terms\n",
    "#                 template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "#                                f\"{gt_method.replace('_','-')}_{h}h_{s}s*[!t].pkl\")\n",
    "#                 pot_pattern = os.path.join(template_path,template_file)\n",
    "#                 pot_paths = glob.glob(pot_pattern)\n",
    "#                 assert len(pot_paths) == 1,\\\n",
    "#                     f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "#                 print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "#                 data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "#                 data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "#                 data_dict['gt_type'] = gt_method\n",
    "#                 return data_dict\n",
    "#             except: pass\n",
    "#         assert False,\"Could not find ground truth\"\n",
    "#         print()\n",
    "#         return None\n",
    "    \n",
    "def get_experiment_data_model_budget(experiment, dataset, h, s, root=\"../data\", \n",
    "            methods=['beam_search_is_hybrid','importance_sampling','random_sampling','beam_search'],\n",
    "            gt_methods=['ground_truth','beam_search']):\n",
    "    \n",
    "        data_dict = {}\n",
    "        gt_type=None\n",
    "        for method in methods:\n",
    "            template_path=root + f\"/{method}/{dataset}/{experiment}/\"\n",
    "            template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\"\n",
    "            + f\"{method.replace('_','-')}_{h}h_{s}s*{'' if method == 'beam_search_is_hybrid' else 'model-budget'}.pkl\")\n",
    "            pot_pattern = os.path.join(template_path,template_file)\n",
    "            pot_paths = glob.glob(pot_pattern)\n",
    "            assert len(pot_paths) == 1,\\\n",
    "                f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "            # print(method,pot_paths[0])\n",
    "            print(method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "            data_dict[method]= read_pkl(pot_paths[0])\n",
    "            data_dict[method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "        for gt_method in gt_methods:\n",
    "            try:\n",
    "                template_path=root + f\"/{gt_method}/{dataset}/{experiment}/\"\n",
    "                template_file=(f\"{experiment.replace('_','-')}_{dataset.replace('_','-')}_\" +\n",
    "                               f\"{gt_method.replace('_','-')}_{h}h_{s}s*.pkl\")\n",
    "                pot_pattern = os.path.join(template_path,template_file)\n",
    "                pot_paths = glob.glob(pot_pattern)\n",
    "                assert len(pot_paths) == 1,\\\n",
    "                    f\"Found {len(pot_paths)} paths for {pot_pattern}\"\n",
    "                print(\"GT: \", gt_method, \"\\n\",pot_paths[0],\"\\n=============\")\n",
    "                data_dict[gt_method]= read_pkl(pot_paths[0])\n",
    "                data_dict[gt_method]['metadata']['result_filepath'] = pot_paths[0]\n",
    "                data_dict['gt_type'] = gt_method\n",
    "                return data_dict\n",
    "            except: pass\n",
    "        assert False,\"Could not find ground truth\"\n",
    "        return None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff8c61a-43ae-4901-8cf0-1f34078701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_search(samp_dict,sub_estimates,search_type=\"beam_search\"):\n",
    "    samp_estimates = samp_dict['bs_lower_bound'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of bs_lower_bounds is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_num_beams'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            beams = pd.DataFrame(samp_dict['num_beams'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            true_cov = pd.DataFrame(samp_dict['true_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            restr_cov = pd.DataFrame(samp_dict['restricted_coverage'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{search_type}_lb',samp_estimates),\n",
    "                ('model_iters',model_iters),\n",
    "                ('num_beams',beams),\n",
    "                ('true_coverage',true_cov),\n",
    "                ('restricted_coverage',restr_cov),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                df[f'{search_type}_{name}']=df[name]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                df[f'{search_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                df[f'{search_type}_num_beams'] = samp_dict['num_beams'][:,i]\n",
    "                df[f'{search_type}_true_coverage'] = samp_dict['true_coverage'][:,i]\n",
    "                df[f'{search_type}_restricted_coverage'] = samp_dict['restricted_coverage'][:,i]\n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['lb','model_iters','num_beams','true_coverage','restricted_coverage']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{search_type}_{s}' for s in res_cols]\n",
    "    df['gt_type'] = 'ground_truth' if search_type=='ground_truth' else 'beam_search'\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def flatten_sampling(samp_dict,sub_estimates,sample_type=\"importance\"):\n",
    "    samp_estimates = samp_dict['sample_estimates'][:,:len(sub_estimates)]\n",
    "    if not sub_estimates:\n",
    "        if len(samp_estimates.shape) ==3:\n",
    "            assert samp_estimates.shape[1] == samp_dict['metadata']['num_mc_samples'],\\\n",
    "            (f\"Error, estimate dimensions are {samp_estimates.shape} but the number of samples is \" +\n",
    "             f\"{samp_dict['metadata']['num_mc_samples']}, which does not match\")\n",
    "            \n",
    "            samp_estimates = torch.gather(samp_estimates.mean(dim=1),1,\n",
    "                                          samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "            assert len(samp_estimates.shape) == 1,f\"Shape of imp_samp_estimates is {len(samp_estimates.shape)}\"\n",
    "        if len(samp_estimates.shape) ==2:\n",
    "            samp_estimates = torch.gather(samp_estimates,1,\n",
    "                                              samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        df = pd.DataFrame(samp_estimates)\n",
    "        df.insert(0,'num_mc_samples',samp_dict['metadata']['num_mc_samples'])\n",
    "        df[f'{sample_type}_model_iters'] = samp_dict['model_iters']\n",
    "        df[f'{sample_type}_est_variance'] = samp_dist['sample_estimate_var']\n",
    "        \n",
    "    else:\n",
    "        assert samp_estimates.shape[1] == len(sub_estimates),\\\n",
    "        (\"Importance sampling estimates and sub_estimates are not aligned in shape.\" +\n",
    "         f\"got sample_est: {samp_estimates.shape[1]} and sub_estimates: {len(sub_estimates)}\")\n",
    "        if len(samp_estimates.shape) == 2:\n",
    "            samp_estimates = pd.DataFrame(samp_estimates,columns=sub_estimates)\n",
    "            samp_var = pd.DataFrame(samp_dict['sample_estimate_var'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            model_iters = pd.DataFrame(samp_dict['model_iters'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            sub_estimate_num_samples = None\n",
    "            if sample_type != 'hybrid':\n",
    "                sub_estimate_num_samples = pd.DataFrame(samp_dict['num_mc_samples'][:,:len(sub_estimates)],columns=sub_estimates)\n",
    "            \n",
    "            df_list = [\n",
    "                (f'{sample_type}_sampling_est',samp_estimates),\n",
    "                ('num_mc_samples',sub_estimate_num_samples),\n",
    "                ('model_iters',model_iters),\n",
    "                ('variance',samp_var),\n",
    "            ]\n",
    "            \n",
    "            for i,(name,df) in enumerate(df_list):\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df = pd.melt(df,value_vars=sub_estimates)\n",
    "                df.columns = ['num_samples',name]\n",
    "            df = df_list[0]\n",
    "            for name,df in df_list[1:]:\n",
    "                if name == 'num_mc_samples' and sample_type==\"hybrid\": continue\n",
    "                df[f'{sample_type}_{name}']=df[name]\n",
    "            if df_type == \"hybrid\":\n",
    "                df['num_mc_samples'] = df['num_samples']\n",
    "                df = df[['num_mc_samples',f'{sample_type}_sampling_est',\n",
    "                         'model_iters','variance']]\n",
    "            \n",
    "            # df[f'{sample_type}_variance']=var_df['variance']\n",
    "            \n",
    "        elif len(samp_estimates.shape) == 3:\n",
    "            df_list = []\n",
    "            for i in range(len(sub_estimates)):\n",
    "                df = pd.DataFrame(\n",
    "                            torch.gather(samp_estimates[:,i],1,\n",
    "                                      samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                        )\n",
    "                if sample_type == \"hybrid\": df.insert(0,'num_mc_samples',sub_estimates[i])\n",
    "                else: df.insert(0,'num_mc_samples',samp_dict['num_mc_samples'][:,i])\n",
    "                df[f'{sample_type}_model_iters'] = samp_dict['model_iters'][:,i]\n",
    "                samp_est_var = torch.gather(samp_dict['sample_estimate_var'][:,i],1,\n",
    "                                            samp_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "                                            \n",
    "                df[f'{sample_type}_variance'] = samp_est_var\n",
    "                \n",
    "                df_list.append(df)\n",
    "            df = pd.concat(df_list,axis=0,ignore_index=True)\n",
    "        else:\n",
    "            assert False,f\"Shape of samp_estimates is {len(samp_estimates.shape)}\"\n",
    "    res_cols = ['num_mc_samples','sampling_est','model_iters','variance']\n",
    "    assert df.shape[-1] == len(res_cols), f\"DF shape is {df.shape}\"\n",
    "    df.columns = [f'{sample_type}_{s}' for s in res_cols]\n",
    "    return df\n",
    "\n",
    "\n",
    "def flatten_gt(data_dict,gt_type):\n",
    "    gt_dict = data_dict[gt_type]\n",
    "    print(gt_dict.keys())\n",
    "    # gt = gt_dict['bs_lower_bound']\n",
    "    gt = torch.gather(gt_dict['bs_lower_bound'],1,\n",
    "                      gt_dict['excluded_terms'].unsqueeze(-1)).squeeze()\n",
    "    assert len(gt.shape) == 1,\\\n",
    "    f\"Ground truth has {len(gt.shape)} dimensions\"\n",
    "    df = pd.DataFrame(gt,columns=['ground_truth'])\n",
    "    for item in ['true_coverage','restricted_coverage','model_iters']:\n",
    "        df[f\"gt_{item}\"] = [gti.item() for gti in gt_dict[item]]\n",
    "    # df[\"gt_model_iters\"] = gt_dict['model_iters']\n",
    "    df['gt_type'] = gt_type\n",
    "    df['gt_num_beams'] = gt_dict['metadata']['num_beams']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def flatten_experiment(data_dict,experiment, dataset,h,s,\n",
    "     global_agreement_vals= ['excluded_terms']):\n",
    "    sub_estimates = sorted(list(\n",
    "        # set(data_dict['importance_sampling']['metadata']['sub_estimates']) &\n",
    "        # set(data_dict['random_sampling']['metadata']['sub_estimates']) &\n",
    "        set(data_dict['beam_search_is_hybrid']['metadata']['sub_estimates'])))\n",
    "    sub_est_len = 1 if not sub_estimates else len(sub_estimates)\n",
    "    \n",
    "    importance_df = flatten_sampling(data_dict['importance_sampling'],sub_estimates,sample_type ='importance')\n",
    "    random_df = flatten_sampling(data_dict['random_sampling'],sub_estimates,sample_type ='random')\n",
    "    hybrid_df = flatten_sampling(data_dict['beam_search_is_hybrid'],sub_estimates,sample_type ='hybrid')\n",
    "    search_df = flatten_search(data_dict['beam_search'],sub_estimates,search_type='beam_search')\n",
    "    # hybrid_df.drop(\"num_mc_samples\",inplace = True,axis=1)\n",
    "    \n",
    "    gt_df = flatten_gt(data_dict,data_dict['gt_type'])\n",
    "    gt_df = pd.concat([gt_df]*sub_est_len,axis=0,ignore_index=True)\n",
    "    final_df = pd.concat([random_df,importance_df,hybrid_df,search_df,gt_df],axis=1)\n",
    "    \n",
    "    # Metadata checks\n",
    "    is_metadata = ['top_k','top_p']\n",
    "    hybrid_metadata = ['min_variance','min_var_reduction']\n",
    "    bs_metadata = []\n",
    "    gt_metadata = []\n",
    "    for m in is_metadata:\n",
    "        final_df['is_' + m] = data_dict['importance_sampling']['metadata'][m]\n",
    "    for m in hybrid_metadata:\n",
    "        final_df['hybrid_' + m] = data_dict['beam_search_is_hybrid']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['bs_lb_' + m] = data_dict['beam_search']['metadata'][m]\n",
    "    for m in bs_metadata:\n",
    "        final_df['gt_' + m] = data_dict[data_dict['gt_type']]['metadata'][m]\n",
    "    final_df['interp_func'] = str(data_dict[data_dict['gt_type']]['metadata']['interp_func']).split(\" \")[1]\n",
    "    \n",
    "    \n",
    "    final_df['dataset_name'] = dataset\n",
    "    final_df['hist_len'] = h\n",
    "    final_df['total_seq_len'] = s\n",
    "    final_df['seq_len'] = s-h\n",
    "    sequence_ids = list(range(data_dict['importance_sampling']['sample_estimates'].shape[0]))*sub_est_len\n",
    "    excluded_terms = data_dict['importance_sampling']['excluded_terms'].numpy().tolist()*sub_est_len\n",
    "    final_df['sequence_id'] = sequence_ids\n",
    "    final_df['excluded_term'] = excluded_terms\n",
    "                 \n",
    "    # ==== Phase shift stuff ====\n",
    "    # phase_shifts = read_pkl(\"/srv/disk00/samshow/amazon/amazon_phase_trans.pkl\")\n",
    "    # phase_shift_val_inds = read_pkl(\"../data/amazon/amazon_val_dl_transition_inds.pkl\")\n",
    "    # phase_shifts = phase_shifts[phase_shift_val_inds].numpy().tolist()\n",
    "    # print(phase_shift_val_inds.shape, final_df.shape)\n",
    "    # final_df['phase_shifts'] = phase_shifts * sub_est_len\n",
    "    # final_df['phase_shifts'] -=1\n",
    "    \n",
    "    return final_df\n",
    "     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb936c89-eb0e-42cd-923b-8a60a9fc167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = [\"val_dl\"]\n",
    "dataset = [\"apps\"]\n",
    "lengths = [(13,15),(12,15)]\n",
    "def flatten_experiments(experiments, datasets, lengths,model_budget=False):\n",
    "    data_list = []\n",
    "    for experiment in experiments:\n",
    "        for dataset in datasets:\n",
    "            for h,s in lengths:\n",
    "                # try:\n",
    "                    \n",
    "                    if model_budget:\n",
    "                        data = get_experiment_data(experiment,dataset,h,s)\n",
    "                    else:\n",
    "                        data = get_experiment_data_model_budget(experiment,dataset,h,s)\n",
    "                        \n",
    "                    df = flatten_experiment(data,experiment, dataset, h,s)\n",
    "                    \n",
    "#                     print(df.head())\n",
    "#                     print(df.columns)\n",
    "#                     print(df.shape)\n",
    "#                     sys.exit(1)\n",
    "                    \n",
    "                    data_list.append(df)\n",
    "                    \n",
    "    # print(len(data_list))\n",
    "    data_df = pd.concat(data_list,axis = 0)\n",
    "    ordering = [ 'dataset_name','sequence_id','seq_len', 'excluded_term', 'gt_type','ground_truth',\n",
    "                'random_sampling_est','importance_sampling_est','hybrid_sampling_est', 'beam_search_lb',\n",
    "                'random_num_mc_samples', 'importance_num_mc_samples','hybrid_num_mc_samples',\n",
    "                'gt_model_iters','random_model_iters', #continues to next line\n",
    "                'importance_model_iters','hybrid_model_iters','beam_search_model_iters',\n",
    "                'random_variance','importance_variance',  'hybrid_variance',\n",
    "                'gt_true_coverage', 'gt_restricted_coverage', 'gt_num_beams',\n",
    "                'beam_search_true_coverage', 'beam_search_restricted_coverage', 'beam_search_num_beams',\n",
    "                'is_top_k','is_top_p',\n",
    "                'hybrid_min_variance','hybrid_min_var_reduction', \n",
    "                'interp_func','hist_len', 'total_seq_len']#, 'phase_shifts']\n",
    "    data_df = data_df[ordering]\n",
    "    print(data_df.columns)\n",
    "    \n",
    "    return data_df\n",
    "                \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62c51bbf-1517-42cc-8ed2-b99b496d041f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/shakespeare/val_dl/val-dl_shakespeare_beam-search-is-hybrid_18h_20s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/shakespeare/val_dl/val-dl_shakespeare_importance-sampling_18h_20s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/shakespeare/val_dl/val-dl_shakespeare_random-sampling_18h_20s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/shakespeare/val_dl/val-dl_shakespeare_beam-search_18h_20s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/shakespeare/val_dl/val-dl_shakespeare_ground-truth_18h_20s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/shakespeare/val_dl/val-dl_shakespeare_beam-search-is-hybrid_17h_20s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/shakespeare/val_dl/val-dl_shakespeare_importance-sampling_17h_20s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/shakespeare/val_dl/val-dl_shakespeare_random-sampling_17h_20s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/shakespeare/val_dl/val-dl_shakespeare_beam-search_17h_20s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/shakespeare/val_dl/val-dl_shakespeare_ground-truth_17h_20s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "Index(['dataset_name', 'sequence_id', 'seq_len', 'excluded_term', 'gt_type',\n",
      "       'gt_type', 'ground_truth', 'random_sampling_est',\n",
      "       'importance_sampling_est', 'hybrid_sampling_est', 'beam_search_lb',\n",
      "       'random_num_mc_samples', 'importance_num_mc_samples',\n",
      "       'hybrid_num_mc_samples', 'gt_model_iters', 'random_model_iters',\n",
      "       'importance_model_iters', 'hybrid_model_iters',\n",
      "       'beam_search_model_iters', 'random_variance', 'importance_variance',\n",
      "       'hybrid_variance', 'gt_true_coverage', 'gt_restricted_coverage',\n",
      "       'gt_num_beams', 'beam_search_true_coverage',\n",
      "       'beam_search_restricted_coverage', 'beam_search_num_beams', 'is_top_k',\n",
      "       'is_top_p', 'hybrid_min_variance', 'hybrid_min_var_reduction',\n",
      "       'interp_func', 'hist_len', 'total_seq_len'],\n",
      "      dtype='object')\n",
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/apps/val_dl/val-dl_apps_beam-search-is-hybrid_13h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/apps/val_dl/val-dl_apps_importance-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/apps/val_dl/val-dl_apps_random-sampling_13h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/apps/val_dl/val-dl_apps_beam-search_13h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/apps/val_dl/val-dl_apps_ground-truth_13h_15s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "beam_search_is_hybrid \n",
      " ../data/beam_search_is_hybrid/apps/val_dl/val-dl_apps_beam-search-is-hybrid_12h_15s_1000mc.pkl \n",
      "=============\n",
      "importance_sampling \n",
      " ../data/importance_sampling/apps/val_dl/val-dl_apps_importance-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "random_sampling \n",
      " ../data/random_sampling/apps/val_dl/val-dl_apps_random-sampling_12h_15s_1000mc_model-budget.pkl \n",
      "=============\n",
      "beam_search \n",
      " ../data/beam_search/apps/val_dl/val-dl_apps_beam-search_12h_15s_model-budget.pkl \n",
      "=============\n",
      "GT:  ground_truth \n",
      " ../data/ground_truth/apps/val_dl/val-dl_apps_ground-truth_12h_15s.pkl \n",
      "=============\n",
      "dict_keys(['true_coverage', 'restricted_coverage', 'num_beams', 'model_iters', 'bs_lower_bound', 'intermediate_lbs', 'metadata', 'excluded_terms'])\n",
      "Index(['dataset_name', 'sequence_id', 'seq_len', 'excluded_term', 'gt_type',\n",
      "       'gt_type', 'ground_truth', 'random_sampling_est',\n",
      "       'importance_sampling_est', 'hybrid_sampling_est', 'beam_search_lb',\n",
      "       'random_num_mc_samples', 'importance_num_mc_samples',\n",
      "       'hybrid_num_mc_samples', 'gt_model_iters', 'random_model_iters',\n",
      "       'importance_model_iters', 'hybrid_model_iters',\n",
      "       'beam_search_model_iters', 'random_variance', 'importance_variance',\n",
      "       'hybrid_variance', 'gt_true_coverage', 'gt_restricted_coverage',\n",
      "       'gt_num_beams', 'beam_search_true_coverage',\n",
      "       'beam_search_restricted_coverage', 'beam_search_num_beams', 'is_top_k',\n",
      "       'is_top_p', 'hybrid_min_variance', 'hybrid_min_var_reduction',\n",
      "       'interp_func', 'hist_len', 'total_seq_len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = flatten_experiments(['val_dl'],['shakespeare'],[(18,20),(17,20)])\n",
    "# df1 = flatten_experiments(['val_dl'],['shakespeare'],[(18,20),(17,20)])\n",
    "# df = flatten_experiments(['val_dl'],['amazon'],[(13,15),(12,15)])\n",
    "df = flatten_experiments(['val_dl'],['apps'],[(13,15),(12,15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686d012-ca67-4160-aace-cabe4dc2d6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce843b1-19fd-4a08-bd5e-a76576456916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_model_iters</th>\n",
       "      <th>hybrid_model_iters</th>\n",
       "      <th>beam_search_model_iters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10909</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>2964</td>\n",
       "      <td>2963</td>\n",
       "      <td>2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>2628</td>\n",
       "      <td>2628</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>2976</td>\n",
       "      <td>2975</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>3000</td>\n",
       "      <td>2998</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10915</th>\n",
       "      <td>2730</td>\n",
       "      <td>2730</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10916</th>\n",
       "      <td>2922</td>\n",
       "      <td>2922</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>2565</td>\n",
       "      <td>2564</td>\n",
       "      <td>2565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10918</th>\n",
       "      <td>2046</td>\n",
       "      <td>2045</td>\n",
       "      <td>2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10920</th>\n",
       "      <td>2985</td>\n",
       "      <td>2983</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10921</th>\n",
       "      <td>2940</td>\n",
       "      <td>2938</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10922</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10923</th>\n",
       "      <td>2967</td>\n",
       "      <td>2965</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>2943</td>\n",
       "      <td>2941</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10925</th>\n",
       "      <td>3000</td>\n",
       "      <td>2999</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10926</th>\n",
       "      <td>2505</td>\n",
       "      <td>2503</td>\n",
       "      <td>2505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10927</th>\n",
       "      <td>2430</td>\n",
       "      <td>2430</td>\n",
       "      <td>2431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10928</th>\n",
       "      <td>1653</td>\n",
       "      <td>1651</td>\n",
       "      <td>1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10929</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10930</th>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "      <td>2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "      <td>1695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10932</th>\n",
       "      <td>2979</td>\n",
       "      <td>2978</td>\n",
       "      <td>2979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10933</th>\n",
       "      <td>2967</td>\n",
       "      <td>2966</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10934</th>\n",
       "      <td>2688</td>\n",
       "      <td>2688</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10935</th>\n",
       "      <td>1938</td>\n",
       "      <td>1936</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>1662</td>\n",
       "      <td>1660</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>2520</td>\n",
       "      <td>2520</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>1674</td>\n",
       "      <td>1673</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10941</th>\n",
       "      <td>2940</td>\n",
       "      <td>2940</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10942</th>\n",
       "      <td>2799</td>\n",
       "      <td>2798</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10943</th>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "      <td>2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10944</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10945</th>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10946</th>\n",
       "      <td>2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10947</th>\n",
       "      <td>2916</td>\n",
       "      <td>2914</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10948</th>\n",
       "      <td>2559</td>\n",
       "      <td>2558</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10949</th>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "      <td>2949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10951</th>\n",
       "      <td>2385</td>\n",
       "      <td>2383</td>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10952</th>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10953</th>\n",
       "      <td>2844</td>\n",
       "      <td>2842</td>\n",
       "      <td>2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10954</th>\n",
       "      <td>2883</td>\n",
       "      <td>2881</td>\n",
       "      <td>2883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>1752</td>\n",
       "      <td>1751</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>2655</td>\n",
       "      <td>2653</td>\n",
       "      <td>2655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_model_iters  hybrid_model_iters  beam_search_model_iters\n",
       "10909                    2019                2019                     2019\n",
       "10910                    2964                2963                     2965\n",
       "10911                    2919                2919                     2919\n",
       "10912                    2628                2628                     2629\n",
       "10913                    2976                2975                     2977\n",
       "10914                    3000                2998                     3001\n",
       "10915                    2730                2730                     2731\n",
       "10916                    2922                2922                     2923\n",
       "10917                    2565                2564                     2565\n",
       "10918                    2046                2045                     2047\n",
       "10919                    2985                2985                     2985\n",
       "10920                    2985                2983                     2985\n",
       "10921                    2940                2938                     2941\n",
       "10922                    2967                2966                     2967\n",
       "10923                    2967                2965                     2967\n",
       "10924                    2943                2941                     2943\n",
       "10925                    3000                2999                     3001\n",
       "10926                    2505                2503                     2505\n",
       "10927                    2430                2430                     2431\n",
       "10928                    1653                1651                     1653\n",
       "10929                    2979                2978                     2979\n",
       "10930                    2991                2991                     2991\n",
       "10931                    1695                1695                     1695\n",
       "10932                    2979                2978                     2979\n",
       "10933                    2967                2966                     2967\n",
       "10934                    2688                2688                     2689\n",
       "10935                    1938                1936                     1939\n",
       "10936                    1662                1660                     1663\n",
       "10937                    2589                2589                     2589\n",
       "10938                    2520                2520                     2521\n",
       "10939                    1674                1673                     1675\n",
       "10940                    2967                2967                     2967\n",
       "10941                    2940                2940                     2941\n",
       "10942                    2799                2798                     2799\n",
       "10943                    2859                2859                     2859\n",
       "10944                    3003                3003                     3003\n",
       "10945                    2895                2895                     2895\n",
       "10946                    2040                2040                     2041\n",
       "10947                    2916                2914                     2917\n",
       "10948                    2559                2558                     2559\n",
       "10949                    2949                2949                     2949\n",
       "10950                    1881                1881                     1881\n",
       "10951                    2385                2383                     2385\n",
       "10952                    3003                3003                     3003\n",
       "10953                    2844                2842                     2845\n",
       "10954                    2883                2881                     2883\n",
       "10955                    2997                2997                     2997\n",
       "10956                    1752                1751                     1753\n",
       "10957                    2655                2653                     2655\n",
       "10958                    2139                2139                     2139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['importance_sampling']['metadata']['sub_estimates']\n",
    "# print(df.shape)\n",
    "# print(df.isnull().sum())\n",
    "# df.phase_shifts.describe()\n",
    "# df[['importance_model_iters','hybrid_model_iters','beam_search_model_iters']].tail(50)\n",
    "# df[['hybrid_num_mc_samples', 'importance_num_mc_samples','beam_search_num_beams']].head(50)\n",
    "# df[['beam_search_true_coverage','beam_search_restricted_coverage','beam_search_num_beams']].tail(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81963683-e69a-4cbf-be8f-970918de1117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15b17f57-5661-4ffc-8b42-d94827b114ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.020524\n",
       "0    0.016677\n",
       "Name: hybrid_sampling_est, dtype: float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hybrid_sampling_est[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b010b1e-e070-4f9b-85bf-141fd935acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'importance')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = df[df['phase_shifts'] > 10]\n",
    "# df = df1\n",
    "plt.scatter(df['ground_truth'],df['hybrid_sampling_est'])\n",
    "plt.title(\"importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3e8a10-b1b5-4498-bc4a-90eaa5ecbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_est_variance</th>\n",
       "      <th>hybrid_est_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.191800e+04</td>\n",
       "      <td>2.191800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.688037e-05</td>\n",
       "      <td>3.907905e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.492985e-04</td>\n",
       "      <td>8.797111e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.860333e-20</td>\n",
       "      <td>1.116206e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.422974e-09</td>\n",
       "      <td>1.191007e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.011587e-08</td>\n",
       "      <td>1.700204e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.072154e-07</td>\n",
       "      <td>1.139661e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.445925e-02</td>\n",
       "      <td>4.038442e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       importance_est_variance  hybrid_est_variance\n",
       "count             2.191800e+04         2.191800e+04\n",
       "mean              3.688037e-05         3.907905e-06\n",
       "std               6.492985e-04         8.797111e-05\n",
       "min               2.860333e-20         1.116206e-19\n",
       "25%               4.422974e-09         1.191007e-09\n",
       "50%               4.011587e-08         1.700204e-08\n",
       "75%               3.072154e-07         1.139661e-07\n",
       "max               4.445925e-02         4.038442e-03"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['importance_est_variance','hybrid_est_variance']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed16f5a-8501-46b6-8e3e-3d4f3a55b259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name               0\n",
       "sequence_id                0\n",
       "seq_len                    0\n",
       "excluded_term              0\n",
       "gt_type                    0\n",
       "ground_truth               0\n",
       "importance_sampling_est    0\n",
       "hybrid_sampling_est        0\n",
       "num_mc_samples             0\n",
       "importance_model_iters     0\n",
       "hybrid_model_iters         0\n",
       "importance_est_variance    0\n",
       "hybrid_est_variance        0\n",
       "true_coverage              0\n",
       "restricted_coverage        0\n",
       "top_k                      0\n",
       "top_p                      0\n",
       "min_variance               0\n",
       "min_var_reduction          0\n",
       "num_beams                  0\n",
       "interp_func                0\n",
       "hist_len                   0\n",
       "total_seq_len              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a52b7fd-4659-494d-9ff3-13584d46e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('shakespeare_17-18_20.csv',index=None)\n",
    "df.to_csv('moocs_12-13_15.csv',index=None)\n",
    "# df3.to_csv('apps_12-13_15.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ea7d4da0-609f-40e6-ad58-0c5d761c8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dict = read_pkl(\"/srv/disk00/samshow/amazon/amazon_text_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb6f3eab-1f61-4c3e-bf7c-2ff76eb144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon_dict['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19594098-def2-47ac-8f3a-059d760179fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580, 16])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0b0cc01-7d4b-4203-88ea-d367dd1d10cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 16., 16., 16., 11.,  3., 27., 27.,  9.,  9.,  9., 23., 16., 16.,\n",
       "        16.,  8.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c73676-c082-46a2-997d-1cea95e17256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63844580/63844580 [17:23<00:00, 61164.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "trans = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    trans.append(torch.unique_consecutive(data[i,1:]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b36271e-5d00-43d2-af28-de548ec74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torch.LongTensor(trans).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c83ae82d-e144-4f7b-9fa1-855591a0f8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63844580])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36efdf43-a1a5-43b0-97c4-9f85633c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pkl(trans, \"/srv/disask00/samshow/amazon/amazon_phase_trans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60ad3b21-6ab1-4788-af46-5b60a4823228",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_vals = []\n",
    "for i in range(1,trans.max()+1):\n",
    "    trans_vals.append((trans == i).sum().item()/trans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "299b9ef8-a587-479e-821d-6b244e68101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_perc_per_phase_shift = [0.059163910233257073,\n",
    " 0.020707521296247856,\n",
    " 0.056485656260876024,\n",
    " 0.04778584180520884,\n",
    " 0.07297364944682853,\n",
    " 0.07653857226408256,\n",
    " 0.09382401763783238,\n",
    " 0.10168632952084578,\n",
    " 0.1102257544806466,\n",
    " 0.10986890351538063,\n",
    " 0.09992870185691566,\n",
    " 0.0774158276238954,\n",
    " 0.047934671979986396,\n",
    " 0.020711280425057224,\n",
    " 0.004749361652939059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726ba0a-3b52-4c66-93bd-57bbea35dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
